{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85502236",
   "metadata": {},
   "source": [
    "# A5 å°æ›¸ç”¢ç”Ÿå™¨ï¼ˆv8ï¼‰â€” å¥½ç”¨çš„åœ–ç‰‡ä¸Šå‚³ï¼šå°é¢ï¼å…§é ï¼å°åº•å„æœ‰è‡ªå·±çš„é¸æ“‡å™¨\n",
    "\n",
    "- âœ… **å°é¢ã€å…§é ã€å°åº•** å„è‡ªæœ‰åœ–ç‰‡ä¸Šå‚³å€ï¼ˆ`FileUpload`ï¼‰  \n",
    "- âœ… ä¹Ÿæä¾› **URL/Base64 å‚™æ´æ¬„ä½**ï¼ˆè‹¥è¡Œå‹•è£ç½®ä¸Šå‚³ä¸ç©©ï¼Œå¯è²¼é€£çµæˆ– base64ï¼Œæ¯è¡Œä¸€å¼µï¼‰  \n",
    "- âœ… ä¸‹è¼‰èµ° **Base64 é€£çµ**ï¼Œé¿é–‹ 403/424  \n",
    "- âœ… æ–‡å­—æ¨™è¨˜ï¼š`[14pt]`ã€`[åœ–ç‰‡]`ã€`[åœ–ç‰‡60%]`ã€`[å·¦åœ–80%][å³åœ–50%]`ã€`[ç„¡åœ–]`  \n",
    "- âœ… å°é¢/å°åº•è‹¥ä¸Šå‚³äº†åœ–ï¼Œæœƒä¾ä½ åœ¨è©²å€æ–‡å­—ä¸­å‡ºç¾çš„ `[åœ–ç‰‡]`/`[åœ–ç‰‡60%]` æ”¾å…¥ï¼›æ²’æœ‰æ¨™è¨˜ä¹Ÿæœƒè‡ªå‹•é™„åœ¨æ–‡å¾Œ\n",
    "\n",
    "**å»ºè­°**ï¼šæ¡Œæ©Ÿç”¨ Chrome/Firefox é«”é©—æœ€ä½³ï¼›è¡Œå‹•è£ç½®è‹¥ `FileUpload` ä¸ç©©ï¼Œè«‹æ”¹ç”¨ URL/Base64 å‚™æ´ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51e6f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import io, re, base64, urllib.request, time\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "from docx import Document\n",
    "from docx.shared import Mm, Pt, Inches\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "from docx.oxml import OxmlElement\n",
    "from docx.oxml.ns import qn\n",
    "\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c92751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "\n",
    "def ensure_rgb_jpeg(img_bytes, quality=90):\n",
    "    im = Image.open(io.BytesIO(img_bytes))\n",
    "    if im.mode not in (\"RGB\", \"L\"):\n",
    "        im = im.convert(\"RGB\")\n",
    "    out = io.BytesIO()\n",
    "    im.save(out, format=\"JPEG\", quality=quality)\n",
    "    return out.getvalue()\n",
    "\n",
    "def parse_size_tag(text, default_pt=12):\n",
    "    m = re.search(r\"\\[(\\d+)pt\\]\\s*$\", text)\n",
    "    return int(m.group(1)) if m else default_pt\n",
    "\n",
    "def strip_size_tag(text):\n",
    "    return re.sub(r\"\\[\\d+pt\\]\\s*$\", \"\", text)\n",
    "\n",
    "def has_skip_image_tag(text):\n",
    "    return bool(re.search(r\"\\[ç„¡åœ–\\]\\s*$\", text))\n",
    "\n",
    "def strip_skip_image_tag(text):\n",
    "    return re.sub(r\"\\[ç„¡åœ–\\]\\s*$\", \"\", text)\n",
    "\n",
    "def find_single_image_tag(text):\n",
    "    m = re.search(r\"\\[(?:åœ–ç‰‡)(\\d+)?%?\\]\", text)\n",
    "    if not m:\n",
    "        return None\n",
    "    pct = m.group(1)\n",
    "    pct = int(pct) if pct else None\n",
    "    return (pct, m.start(), m.end())\n",
    "\n",
    "def find_double_image_tags(text):\n",
    "    ml = re.search(r\"\\[å·¦åœ–(\\d+)?%?\\]\", text)\n",
    "    mr = re.search(r\"\\[å³åœ–(\\d+)?%?\\]\", text)\n",
    "    if not (ml and mr):\n",
    "        return None\n",
    "    lp = int(ml.group(1)) if ml.group(1) else None\n",
    "    rp = int(mr.group(1)) if mr.group(1) else None\n",
    "    return (lp, rp)\n",
    "\n",
    "def set_section_to_a5(section):\n",
    "    section.page_width = Mm(148)\n",
    "    section.page_height = Mm(210)\n",
    "    section.left_margin = Mm(15)\n",
    "    section.right_margin = Mm(15)\n",
    "    section.top_margin = Mm(15)\n",
    "    section.bottom_margin = Mm(15)\n",
    "\n",
    "def add_paragraph_with_size(doc, text, size_pt, align_center=False):\n",
    "    p = doc.add_paragraph(text)\n",
    "    p.alignment = WD_ALIGN_PARAGRAPH.CENTER if align_center else WD_ALIGN_PARAGRAPH.LEFT\n",
    "    for run in p.runs:\n",
    "        run.font.size = Pt(size_pt)\n",
    "    return p\n",
    "\n",
    "def add_single_image_paragraph(doc, img_bytes, width_pct=None):\n",
    "    page_w_mm = 148 - 15 - 15\n",
    "    page_w_in = page_w_mm / 25.4\n",
    "    if width_pct is None:\n",
    "        width_in = page_w_in * 0.9\n",
    "    else:\n",
    "        width_in = page_w_in * (width_pct / 100.0)\n",
    "        width_in = max(1.0, min(page_w_in, width_in))\n",
    "    safe = ensure_rgb_jpeg(img_bytes)\n",
    "    doc.add_picture(io.BytesIO(safe), width=Inches(width_in))\n",
    "\n",
    "def add_double_image_table(doc, left_bytes, right_bytes, l_pct, r_pct):\n",
    "    page_w_mm = 148 - 15 - 15\n",
    "    page_w_in = page_w_mm / 25.4\n",
    "    base_in = page_w_in / 2.0\n",
    "    l_in = base_in if l_pct is None else base_in * (l_pct / 100.0)\n",
    "    r_in = base_in if r_pct is None else base_in * (r_pct / 100.0)\n",
    "    l_in = max(1.0, min(page_w_in, l_in))\n",
    "    r_in = max(1.0, min(page_w_in, r_in))\n",
    "\n",
    "    table = doc.add_table(rows=1, cols=2)\n",
    "    table.autofit = True\n",
    "    cell = table.rows[0].cells[0]\n",
    "    run = cell.paragraphs[0].add_run()\n",
    "    run.add_picture(io.BytesIO(ensure_rgb_jpeg(left_bytes)), width=Inches(l_in))\n",
    "    cell = table.rows[0].cells[1]\n",
    "    run = cell.paragraphs[0].add_run()\n",
    "    run.add_picture(io.BytesIO(ensure_rgb_jpeg(right_bytes)), width=Inches(r_in))\n",
    "\n",
    "def add_page_number_footer(section, start_from=1):\n",
    "    footer = section.footer\n",
    "    p = footer.paragraphs[0] if footer.paragraphs else footer.add_paragraph()\n",
    "    p.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "    fld_simple = OxmlElement('w:fldSimple'); fld_simple.set(qn('w:instr'), 'PAGE')\n",
    "    r = OxmlElement('w:r'); t = OxmlElement('w:t'); t.text = \" \"; r.append(t); fld_simple.append(r)\n",
    "    p._p.append(fld_simple)\n",
    "    sectPr = section._sectPr\n",
    "    nodes = sectPr.xpath('./w:pgNumType')\n",
    "    if nodes:\n",
    "        pg = nodes[0]\n",
    "    else:\n",
    "        pg = OxmlElement('w:pgNumType'); sectPr.append(pg)\n",
    "    pg.set(qn('w:start'), str(start_from))\n",
    "\n",
    "def load_image_from_line(line: str) -> bytes:\n",
    "    line = line.strip()\n",
    "    if not line:\n",
    "        return None\n",
    "    if line.startswith('data:image'):\n",
    "        head, b64 = line.split(',', 1)\n",
    "        return base64.b64decode(b64)\n",
    "    if line.startswith('http://') or line.startswith('https://'):\n",
    "        with urllib.request.urlopen(line) as resp:\n",
    "            return resp.read()\n",
    "    # pure base64\n",
    "    try:\n",
    "        return base64.b64decode(line, validate=True)\n",
    "    except Exception:\n",
    "        raise ValueError(\"ç„¡æ³•è¾¨è­˜çš„åœ–ç‰‡è¼¸å…¥ï¼šè«‹æä¾›åœ–ç‰‡ URLã€data:base64 æˆ–ç´” base64ã€‚\")\n",
    "\n",
    "def make_data_uri_download(data: bytes, filename: str) -> HTML:\n",
    "    b64 = base64.b64encode(data).decode()\n",
    "    href = f'<a download=\"{filename}\" href=\"data:application/vnd.openxmlformats-officedocument.wordprocessingml.document;base64,{b64}\">ğŸ“¥ é»æ­¤ä¸‹è¼‰ {filename}</a>'\n",
    "    return HTML(href)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cbf2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UIï¼šå°é¢ / å…§é  / å°åº• å„è‡ªçš„åœ–ç‰‡ä¾†æºï¼ˆFileUpload + URL/Base64 å‚™æ´ï¼‰\n",
    "\n",
    "# æ–‡æœ¬\n",
    "txt_cover = widgets.Textarea(\n",
    "    value=\"æˆ‘çš„ A5 å°æ›¸\\nï¼ˆé€™æ˜¯å°é¢ï¼Œæœƒç½®ä¸­ï¼‰\\n[åœ–ç‰‡60%]\",\n",
    "    description='å°é¢æ–‡å­—',\n",
    "    layout=widgets.Layout(width='100%', height='90px')\n",
    ")\n",
    "txt_body = widgets.Textarea(\n",
    "    value=(\n",
    "        \"ç¬¬ä¸€ç« â€¦â€¦\\n[åœ–ç‰‡]\\n\\n\"\n",
    "        \"ç¬¬äºŒç« â€¦â€¦\\n[å·¦åœ–80%][å³åœ–60%]\\n\"\n",
    "        \"è‹¥ä¸æƒ³æ¶ˆè€—åœ–ç‰‡ï¼Œå³ä½¿æ®µè½å«[åœ–ç‰‡]ï¼Œå¯åœ¨å°¾ç«¯åŠ [ç„¡åœ–]\\n\"\n",
    "    ),\n",
    "    description='å…§é æ–‡å­—',\n",
    "    layout=widgets.Layout(width='100%', height='180px')\n",
    ")\n",
    "txt_back = widgets.Textarea(\n",
    "    value=\"å°åº•ç°¡ä»‹â€¦â€¦\\n[åœ–ç‰‡60%]\",\n",
    "    description='å°åº•æ–‡å­—',\n",
    "    layout=widgets.Layout(width='100%', height='90px')\n",
    ")\n",
    "\n",
    "# é ç¢¼\n",
    "chk_pagenum = widgets.Checkbox(value=True, description='å…§é åŠ é ç¢¼')\n",
    "\n",
    "# åœ–ç‰‡ï¼šå°é¢ï¼ˆå–®å¼µï¼‰\n",
    "up_cover = widgets.FileUpload(accept='image/*', multiple=False, description='ä¸Šå‚³å°é¢åœ–ï¼ˆå–®å¼µï¼‰')\n",
    "cover_urls = widgets.Textarea(placeholder='å°é¢åœ– URL æˆ– base64ï¼Œä¸€è¡Œä¸€å¼µï¼ˆé€šå¸¸åªéœ€ä¸€å¼µï¼‰', layout=widgets.Layout(height='60px'))\n",
    "\n",
    "# åœ–ç‰‡ï¼šå…§é ï¼ˆå¤šå¼µï¼Œä¾ä¸Šå‚³é †åºï¼‰\n",
    "up_body = widgets.FileUpload(accept='image/*', multiple=True, description='ä¸Šå‚³å…§é åœ–ï¼ˆå¯å¤šå¼µï¼‰')\n",
    "body_urls = widgets.Textarea(placeholder='å…§é åœ– URL æˆ– base64ï¼Œæ¯è¡Œä¸€å¼µï¼ˆä¾å…ˆå¾Œä½¿ç”¨ï¼‰', layout=widgets.Layout(height='90px'))\n",
    "\n",
    "# åœ–ç‰‡ï¼šå°åº•ï¼ˆå–®å¼µï¼‰\n",
    "up_back = widgets.FileUpload(accept='image/*', multiple=False, description='ä¸Šå‚³å°åº•åœ–ï¼ˆå–®å¼µï¼‰')\n",
    "back_urls = widgets.Textarea(placeholder='å°åº•åœ– URL æˆ– base64ï¼Œä¸€è¡Œä¸€å¼µï¼ˆé€šå¸¸åªéœ€ä¸€å¼µï¼‰', layout=widgets.Layout(height='60px'))\n",
    "\n",
    "btn = widgets.Button(description=\"ç”Ÿæˆ A5 å°æ›¸ï¼ˆdocxï¼‰\", button_style='success')\n",
    "out = widgets.Output()\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HBox([widgets.VBox([txt_cover, txt_back]), widgets.VBox([chk_pagenum])]),\n",
    "    widgets.Label('â€”â€” å…§é  â€”â€”'),\n",
    "    txt_body,\n",
    "    widgets.Label('â€”â€” å°é¢åœ–ç‰‡ â€”â€”'),\n",
    "    widgets.HBox([up_cover, cover_urls]),\n",
    "    widgets.Label('â€”â€” å…§é åœ–ç‰‡ï¼ˆä¾ä¸Šå‚³/è¼¸å…¥å…ˆå¾Œï¼‰ â€”â€”'),\n",
    "    widgets.HBox([up_body, body_urls]),\n",
    "    widgets.Label('â€”â€” å°åº•åœ–ç‰‡ â€”â€”'),\n",
    "    widgets.HBox([up_back, back_urls]),\n",
    "    btn,\n",
    "    out\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f46f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# çµ„è£ DOCXï¼ˆæ”¯æ´å°é¢/å…§é /å°åº•ä¸‰çµ„åœ–ç‰‡ä¾†æºï¼‰\n",
    "\n",
    "def gather_bytes_from_uploader(upld, allow_many=False):\n",
    "    data = []\n",
    "    for meta in upld.value:\n",
    "        raw = meta.get('content', b'')\n",
    "        if raw:\n",
    "            data.append(raw)\n",
    "        if (not allow_many) and data:\n",
    "            break\n",
    "    return data\n",
    "\n",
    "def gather_bytes_from_textarea(txt, allow_many=False):\n",
    "    lines = [ln.strip() for ln in txt.value.splitlines() if ln.strip()]\n",
    "    data = []\n",
    "    for ln in lines:\n",
    "        try:\n",
    "            b = load_image_from_line(ln)\n",
    "            if b:\n",
    "                data.append(b)\n",
    "        except Exception:\n",
    "            pass\n",
    "        if (not allow_many) and data:\n",
    "            break\n",
    "    return data\n",
    "\n",
    "def build_docx_with_cover_body_back():\n",
    "    # æ–‡å­—\n",
    "    cover_text = txt_cover.value\n",
    "    body_text  = txt_body.value\n",
    "    back_text  = txt_back.value\n",
    "\n",
    "    # å°é¢åœ–ï¼šå…ˆå–ä¸Šå‚³ï¼›è‹¥ç„¡å†å– URL/base64\n",
    "    cover_imgs = gather_bytes_from_uploader(up_cover, allow_many=False)\n",
    "    if not cover_imgs:\n",
    "        cover_imgs = gather_bytes_from_textarea(cover_urls, allow_many=False)\n",
    "\n",
    "    # å…§é åœ–ï¼šä¸Šå‚³ + URL åˆ—è¡¨åˆä½µ\n",
    "    body_imgs = gather_bytes_from_uploader(up_body, allow_many=True) + gather_bytes_from_textarea(body_urls, allow_many=True)\n",
    "\n",
    "    # å°åº•åœ–\n",
    "    back_imgs = gather_bytes_from_uploader(up_back, allow_many=False)\n",
    "    if not back_imgs:\n",
    "        back_imgs = gather_bytes_from_textarea(back_urls, allow_many=False)\n",
    "\n",
    "    # å…ˆå»º DOCX çš„å°é¢\n",
    "    doc = Document()\n",
    "    set_section_to_a5(doc.sections[0])\n",
    "\n",
    "    # å°é¢ï¼šæ–‡å­— + å¯é¸åœ–ç‰‡\n",
    "    size_pt = parse_size_tag(cover_text, default_pt=18)\n",
    "    text = strip_size_tag(cover_text)\n",
    "    single = find_single_image_tag(text)\n",
    "    if single and cover_imgs:\n",
    "        pct, s, e = single\n",
    "        text_clean = (text[:s] + text[e:]).strip()\n",
    "        if text_clean:\n",
    "            add_paragraph_with_size(doc, text_clean, size_pt, align_center=True)\n",
    "        add_single_image_paragraph(doc, cover_imgs[0], width_pct=pct)\n",
    "    else:\n",
    "        add_paragraph_with_size(doc, text.strip(), size_pt, align_center=True)\n",
    "        if cover_imgs:\n",
    "            add_single_image_paragraph(doc, cover_imgs[0], width_pct=60)\n",
    "\n",
    "    # å…§é ï¼šæ–°ç¯€\n",
    "    doc.add_section()\n",
    "    set_section_to_a5(doc.sections[-1])\n",
    "    if chk_pagenum.value:\n",
    "        add_page_number_footer(doc.sections[-1], start_from=1)\n",
    "\n",
    "    # å…§é å…§å®¹ï¼ˆèˆ‡ä¹‹å‰ä¸€è‡´ï¼‰\n",
    "    paragraphs = [p.strip() for p in body_text.split('\\n')]\n",
    "    img_idx = 0\n",
    "    for raw in paragraphs:\n",
    "        if not raw:\n",
    "            doc.add_paragraph(\"\")\n",
    "            continue\n",
    "        size_pt = parse_size_tag(raw, default_pt=12)\n",
    "        text = strip_size_tag(raw)\n",
    "        skip_img = has_skip_image_tag(text)\n",
    "        text = strip_skip_image_tag(text)\n",
    "\n",
    "        dbl = find_double_image_tags(text)\n",
    "        if dbl and (not skip_img) and (img_idx + 1 < len(body_imgs)):\n",
    "            text_clean = re.sub(r\"\\[å·¦åœ–\\d*%?\\]\\s*\\[å³åœ–\\d*%?\\]\", \"\", text).strip()\n",
    "            if text_clean:\n",
    "                add_paragraph_with_size(doc, text_clean, size_pt)\n",
    "            l_pct, r_pct = dbl\n",
    "            add_double_image_table(doc, body_imgs[img_idx], body_imgs[img_idx+1], l_pct, r_pct)\n",
    "            img_idx += 2\n",
    "            continue\n",
    "\n",
    "        single = find_single_image_tag(text)\n",
    "        if single and (not skip_img) and (img_idx < len(body_imgs)):\n",
    "            pct, s, e = single\n",
    "            text_clean = (text[:s] + text[e:]).strip()\n",
    "            if text_clean:\n",
    "                add_paragraph_with_size(doc, text_clean, size_pt)\n",
    "            add_single_image_paragraph(doc, body_imgs[img_idx], width_pct=pct)\n",
    "            img_idx += 1\n",
    "            continue\n",
    "\n",
    "        add_paragraph_with_size(doc, text, size_pt)\n",
    "\n",
    "    # å°åº•ï¼šæ–°ç¯€\n",
    "    doc.add_section()\n",
    "    set_section_to_a5(doc.sections[-1])\n",
    "    size_pt = parse_size_tag(back_text, default_pt=12)\n",
    "    text = strip_size_tag(back_text)\n",
    "    single = find_single_image_tag(text)\n",
    "    if single and back_imgs:\n",
    "        pct, s, e = single\n",
    "        text_clean = (text[:s] + text[e:]).strip()\n",
    "        if text_clean:\n",
    "            add_paragraph_with_size(doc, text_clean, size_pt, align_center=True)\n",
    "        add_single_image_paragraph(doc, back_imgs[0], width_pct=pct)\n",
    "    else:\n",
    "        add_paragraph_with_size(doc, text.strip(), size_pt, align_center=True)\n",
    "        if back_imgs:\n",
    "            add_single_image_paragraph(doc, back_imgs[0], width_pct=60)\n",
    "\n",
    "    # å°è£\n",
    "    buf = io.BytesIO(); doc.save(buf); data = buf.getvalue()\n",
    "    _ = Document(io.BytesIO(data))\n",
    "    return data\n",
    "\n",
    "def on_click(_):\n",
    "    with out:\n",
    "        clear_output()\n",
    "        try:\n",
    "            data = build_docx_with_cover_body_back()\n",
    "            fname = f\"a5_book_{int(time.time())}.docx\"\n",
    "            display(HTML('<div style=\"color:green;\">å®Œæˆï¼</div>'))\n",
    "            display(make_data_uri_download(data, fname))\n",
    "        except Exception as e:\n",
    "            display(HTML(f'<div style=\"color:red;\">å¤±æ•—ï¼š{e}</div>'))\n",
    "\n",
    "btn.on_click(on_click)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
