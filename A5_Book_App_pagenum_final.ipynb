{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d72934c6",
   "metadata": {},
   "source": [
    "# A5 å°æ›¸ç”¢ç”Ÿå™¨ï¼ˆv17ï¼‰â€” æ¯æ®µè‡ªå‹•æ›é å¯åˆ‡æ›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872fdd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, re, base64, urllib.request, time\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from docx import Document\n",
    "from docx.shared import Mm, Pt, Inches\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "from docx.oxml import OxmlElement\n",
    "from docx.oxml.ns import qn\n",
    "from PIL import Image\n",
    "FWP='ï¼…'\n",
    "def ensure_rgb_jpeg(img_bytes, quality=90):\n",
    "    from PIL import Image, ImageFile\n",
    "    ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "    im = Image.open(io.BytesIO(img_bytes))\n",
    "    if im.mode not in ('RGB','L'): im = im.convert('RGB')\n",
    "    out = io.BytesIO(); im.save(out, format='JPEG', quality=quality); return out.getvalue()\n",
    "def parse_and_strip_size_anywhere(text, default_pt=12):\n",
    "    import re\n",
    "    m = re.search(r'\\[(\\d+)pt\\]', text)\n",
    "    if m: size=int(m.group(1)); return size, text[:m.start()]+text[m.end():]\n",
    "    return default_pt, text\n",
    "def has_skip_image_tag(text):\n",
    "    import re\n",
    "    return bool(re.search(r'\\[\\s*ç„¡åœ–\\s*\\]\\s*$', text))\n",
    "def strip_skip_image_tag(text):\n",
    "    import re\n",
    "    return re.sub(r'\\[\\s*ç„¡åœ–\\s*\\]\\s*$', '', text)\n",
    "def tokenize_line(line):\n",
    "    import re\n",
    "    tokens=[]; i=0\n",
    "    pattern=re.compile(r\"\\[\\s*å·¦åœ–\\s*(\\d+)?\\s*[%\"+FWP+\"]?\\s*\\]\\s*\\[\\s*å³åœ–\\s*(\\d+)?\\s*[%\"+FWP+\"]?\\s*\\]|\\[\\s*åœ–ç‰‡\\s*(\\d+)?\\s*[%\"+FWP+\"]?\\s*\\]\")\n",
    "    while True:\n",
    "        m=pattern.search(line,i)\n",
    "        if not m:\n",
    "            tokens.append(('text', line[i:])); break\n",
    "        if m.start()>i: tokens.append(('text', line[i:m.start()]))\n",
    "        if m.group(1) is not None or m.group(2) is not None:\n",
    "            lp=int(m.group(1)) if m.group(1) else None; rp=int(m.group(2)) if m.group(2) else None\n",
    "            tokens.append(('double', lp, rp))\n",
    "        else:\n",
    "            sp=m.group(3); tokens.append(('single', int(sp) if sp else None))\n",
    "        i=m.end()\n",
    "    return tokens\n",
    "def set_section_to_a5(section):\n",
    "    section.page_width=Mm(148); section.page_height=Mm(210)\n",
    "    section.left_margin=Mm(15); section.right_margin=Mm(15)\n",
    "    section.top_margin=Mm(15); section.bottom_margin=Mm(15)\n",
    "def add_text_paragraph(doc, text, size_pt, center=False):\n",
    "    text=text.strip()\n",
    "    if not text: return None\n",
    "    p=doc.add_paragraph(text); p.alignment=WD_ALIGN_PARAGRAPH.CENTER if center else WD_ALIGN_PARAGRAPH.LEFT\n",
    "    for r in p.runs: r.font.size=Pt(size_pt)\n",
    "    return p\n",
    "def add_single_image_paragraph(doc, img_bytes, width_pct=None, center=True):\n",
    "    page_w_mm=148-15-15; page_w_in=page_w_mm/25.4\n",
    "    if width_pct is None: width_in=page_w_in\n",
    "    else:\n",
    "        width_in=page_w_in*(width_pct/100.0); width_in=max(1.0, min(page_w_in, width_in))\n",
    "    safe=ensure_rgb_jpeg(img_bytes); p=doc.add_paragraph(); p.alignment=WD_ALIGN_PARAGRAPH.CENTER if center else WD_ALIGN_PARAGRAPH.LEFT\n",
    "    p.add_run().add_picture(io.BytesIO(safe), width=Inches(width_in))\n",
    "def add_double_image_table(doc, left_bytes, right_bytes, l_pct, r_pct):\n",
    "    page_w_mm=148-15-15; page_w_in=page_w_mm/25.4; padding=0.2\n",
    "    base_in=(page_w_in-padding)/2.0\n",
    "    l_in=base_in if l_pct is None else base_in*(l_pct/100.0)\n",
    "    r_in=base_in if r_pct is None else base_in*(r_pct/100.0)\n",
    "    l_in=max(0.8, min(base_in, l_in)); r_in=max(0.8, min(base_in, r_in))\n",
    "    table=doc.add_table(rows=1, cols=2); table.autofit=True\n",
    "    for ci,b,w in [(0,left_bytes,l_in),(1,right_bytes,r_in)]:\n",
    "        cell=table.rows[0].cells[ci]; para=cell.paragraphs[0]; para.alignment=WD_ALIGN_PARAGRAPH.JUSTIFY\n",
    "        para.add_run().add_picture(io.BytesIO(ensure_rgb_jpeg(b)), width=Inches(w))\n",
    "def add_page_number_footer(section):\n",
    "    footer=section.footer; p=footer.paragraphs[0] if footer.paragraphs else footer.add_paragraph(); p.alignment=WD_ALIGN_PARAGRAPH.CENTER\n",
    "    p.add_run('-'); fld_begin=OxmlElement('w:fldChar'); fld_begin.set(qn('w:fldCharType'),'begin')\n",
    "    instr=OxmlElement('w:instrText'); instr.text=' PAGE '\n",
    "    fld_end=OxmlElement('w:fldChar'); fld_end.set(qn('w:fldCharType'),'end')\n",
    "    r=OxmlElement('w:r'); r.append(fld_begin); r.append(instr); r.append(fld_end); p._p.append(r); p.add_run('-')\n",
    "def make_data_uri_download(data: bytes, filename: str) -> HTML:\n",
    "    b64=base64.b64encode(data).decode()\n",
    "    return HTML(f'<a download=\"{filename}\" href=\"data:application/vnd.openxmlformats-officedocument.wordprocessingml.document;base64,{b64}\">ğŸ“¥ é»æ­¤ä¸‹è¼‰ {filename}</a>')\n",
    "def image_manager(title: str):\n",
    "    uploader = widgets.FileUpload(accept='image/*', multiple=True, description=f'ä¸Šå‚³{title}')\n",
    "    lst = widgets.Select(options=[], rows=6, description='é †åº')\n",
    "    btn_up = widgets.Button(description='ä¸Šç§»'); btn_down = widgets.Button(description='ä¸‹ç§»')\n",
    "    btn_del = widgets.Button(description='åˆªé™¤'); btn_clear = widgets.Button(description='æ¸…ç©º')\n",
    "    add_box = widgets.Textarea(placeholder='è²¼å…¥åœ–ç‰‡ URL æˆ– data:image/...;base64,... æˆ–ç´” base64ï¼ˆæ¯è¡Œä¸€å¼µï¼‰', layout=widgets.Layout(height='70px', width='100%'))\n",
    "    add_btn = widgets.Button(description='æ–°å¢åˆ°æ¸…å–®', button_style='info')\n",
    "    status = widgets.HTML('')\n",
    "    images = []\n",
    "    def refresh():\n",
    "        lst.options=[f\"{i+1:02d}. {it['name']} ({len(it['bytes'])//1024}KB)\" for i,it in enumerate(images)]; lst.index=0 if images else None\n",
    "    def on_upload(change):\n",
    "        nonlocal images\n",
    "        for meta in uploader.value:\n",
    "            content=meta.get('content', b''); name=meta.get('name','image')\n",
    "            if content: images.append({'name':name, 'bytes':content})\n",
    "        uploader.value.clear(); refresh(); status.value=f\"<span style='color:green'>å·²åŠ å…¥ {len(images)} å¼µ</span>\"\n",
    "    uploader.observe(on_upload, names='value')\n",
    "    def move(delta):\n",
    "        if not images or lst.index is None: return\n",
    "        i=lst.index; j=i+delta\n",
    "        if 0<=j<len(images): images[i],images[j]=images[j],images[i]; refresh(); lst.index=j\n",
    "    btn_up.on_click(lambda _: move(-1)); btn_down.on_click(lambda _: move(1))\n",
    "    btn_del.on_click(lambda _: (images.pop(lst.index), refresh()) if (images and lst.index is not None) else None)\n",
    "    btn_clear.on_click(lambda _: (images.clear(), refresh()))\n",
    "    def do_add_from_text(_):\n",
    "        nonlocal images\n",
    "        lines=[ln.strip() for ln in add_box.value.splitlines() if ln.strip()]; added=0\n",
    "        for ln in lines:\n",
    "            try:\n",
    "                if ln.startswith('data:image'): b64=ln.split(',',1)[1]; b=base64.b64decode(b64)\n",
    "                elif ln.startswith('http://') or ln.startswith('https://'):\n",
    "                    with urllib.request.urlopen(ln) as resp: b=resp.read()\n",
    "                else:\n",
    "                    b=base64.b64decode(ln, validate=True)\n",
    "                images.append({'name':f'added_{len(images)+1}.jpg','bytes':b}); added+=1\n",
    "            except Exception:\n",
    "                pass\n",
    "        add_box.value=''; refresh(); status.value=f\"<span style='color:green'>æ–°å¢ {added} å¼µ</span>\" if added else \"<span style='color:#a00'>æ²’æœ‰æˆåŠŸæ–°å¢</span>\"\n",
    "    add_btn.on_click(do_add_from_text)\n",
    "    ui = widgets.VBox([uploader, widgets.HBox([lst, widgets.VBox([btn_up, btn_down, btn_del, btn_clear])]), widgets.HBox([add_box, widgets.VBox([add_btn])]), status])\n",
    "    return ui, images\n",
    "txt_cover = widgets.Textarea(value='æ›¸åæˆ–å£è™Ÿ[18pt]\\n[åœ–ç‰‡50%]\\nç¨®æ˜¯å¸Œæœ›', description='å°é¢æ–‡å­—', layout=widgets.Layout(width='100%', height='150px'))\n",
    "txt_body  = widgets.Textarea(value='ç¬¬ä¸€æ®µæ–‡å­—ã€‚\\n\\nç¬¬äºŒæ®µæ–‡å­—ã€‚\\n\\nç¬¬ä¸‰æ®µæ–‡å­—ã€‚', description='å…§é æ–‡å­—', layout=widgets.Layout(width='100%', height='200px'))\n",
    "txt_back  = widgets.Textarea(value='å°åº•ç°¡ä»‹â€¦â€¦\\n[å·¦åœ–60%][å³åœ–60%]', description='å°åº•æ–‡å­—', layout=widgets.Layout(width='100%', height='150px'))\n",
    "cover_default_pct = widgets.BoundedIntText(value=100, min=10, max=100, step=1, description='å°é¢é è¨­%')\n",
    "body_default_pct  = widgets.BoundedIntText(value=100, min=10, max=100, step=1, description='å…§é é è¨­%')\n",
    "back_default_pct  = widgets.BoundedIntText(value=100, min=10, max=100, step=1, description='å°åº•é è¨­%')\n",
    "chk_pagenum = widgets.Checkbox(value=True, description='å…§é åŠ é ç¢¼ (-1-)')\n",
    "chk_pagebreak = widgets.Checkbox(value=False, description='æ¯æ®µæ–‡å­—è‡ªå‹•æ›é ')\n",
    "ui_cover, imgs_cover = image_manager('å°é¢åœ–ç‰‡ï¼ˆå¯å¤šå¼µï¼‰')\n",
    "ui_body,  imgs_body  = image_manager('å…§é åœ–ç‰‡ï¼ˆå¯å¤šå¼µï¼‰')\n",
    "ui_back,  imgs_back  = image_manager('å°åº•åœ–ç‰‡ï¼ˆå¯å¤šå¼µï¼‰')\n",
    "btn = widgets.Button(description='ç”Ÿæˆ A5 å°æ›¸ï¼ˆdocxï¼‰', button_style='success')\n",
    "out = widgets.Output()\n",
    "display(widgets.VBox([\n",
    "    widgets.HBox([widgets.VBox([txt_cover, cover_default_pct]), widgets.VBox([chk_pagenum, chk_pagebreak])]),\n",
    "    ui_cover,\n",
    "    widgets.Label('â€”â€” å…§é  â€”â€”'),\n",
    "    txt_body,\n",
    "    body_default_pct,\n",
    "    ui_body,\n",
    "    widgets.Label('â€”â€” å°åº• â€”â€”'),\n",
    "    txt_back,\n",
    "    back_default_pct,\n",
    "    ui_back,\n",
    "    btn,\n",
    "    out\n",
    "]))\n",
    "def emit_stream(doc, text, size_pt, imgs, default_pct, center=False):\n",
    "    skip_img = has_skip_image_tag(text); text = strip_skip_image_tag(text)\n",
    "    tokens = tokenize_line(text)\n",
    "    for tk in tokens:\n",
    "        if tk[0]=='text':\n",
    "            add_text_paragraph(doc, tk[1], size_pt, center=center)\n",
    "        elif tk[0]=='single' and (not skip_img) and imgs:\n",
    "            pct = tk[1] if tk[1] is not None else (default_pct or 100)\n",
    "            add_single_image_paragraph(doc, imgs.pop(0), width_pct=pct, center=True)\n",
    "        elif tk[0]=='double' and (not skip_img) and len(imgs)>=2:\n",
    "            lp, rp = tk[1], tk[2]\n",
    "            add_double_image_table(doc, imgs.pop(0), imgs.pop(0), lp, rp)\n",
    "def build_docx_bytes():\n",
    "    cover_text = txt_cover.value; body_text = txt_body.value; back_text = txt_back.value\n",
    "    cover_imgs = [it['bytes'] for it in imgs_cover]\n",
    "    body_imgs  = [it['bytes'] for it in imgs_body]\n",
    "    back_imgs  = [it['bytes'] for it in imgs_back]\n",
    "    cover_pct=int(cover_default_pct.value or 100); body_pct=int(body_default_pct.value or 100); back_pct=int(back_default_pct.value or 100)\n",
    "    doc = Document(); set_section_to_a5(doc.sections[0])\n",
    "    cover_size, cover_text2 = parse_and_strip_size_anywhere(cover_text, default_pt=18)\n",
    "    emit_stream(doc, cover_text2, cover_size, cover_imgs, cover_pct, center=True)\n",
    "    if cover_imgs: add_single_image_paragraph(doc, cover_imgs.pop(0), width_pct=cover_pct, center=True)\n",
    "    doc.add_section(); set_section_to_a5(doc.sections[-1])\n",
    "    # å°åº•ä¸ç¹¼æ‰¿é è…³ï¼Œä¸”æ¸…ç©º\n",
    "    doc.sections[-1].footer.is_linked_to_previous = False\n",
    "    _ = [setattr(p, 'text','') for p in doc.sections[-1].footer.paragraphs]\n",
    "    # å°åº•ä¸ç¹¼æ‰¿é è…³ï¼Œä¸”æ¸…ç©º\n",
    "    doc.sections[-1].footer.is_linked_to_previous = False\n",
    "    _ = [setattr(p, 'text','') for p in doc.sections[-1].footer.paragraphs]\n",
    "    # å…§æ–‡å¾æœ¬ç¯€é–‹å§‹ï¼Œä¸ç¹¼æ‰¿ä¸Šä¸€ç¯€çš„é è…³ï¼ˆç¢ºä¿å°é¢ç„¡é ç¢¼ï¼‰\n",
    "    doc.sections[-1].footer.is_linked_to_previous = False\n",
    "    if chk_pagenum.value: add_page_number_footer(doc.sections[-1])\n",
    "    raw_lines = body_text.split('\\n')\n",
    "    non_empty = [ln for ln in raw_lines if ln.strip()!='']\n",
    "    total = len(non_empty); done = 0\n",
    "    for raw in raw_lines:\n",
    "        line = raw.strip()\n",
    "        if line=='': doc.add_paragraph(''); continue\n",
    "        size_pt, text = parse_and_strip_size_anywhere(line, default_pt=12)\n",
    "        tokens = tokenize_line(text)\n",
    "        has_tag = any(tk[0] != 'text' for tk in tokens)\n",
    "        emit_stream(doc, text, size_pt, body_imgs, body_pct, center=False)\n",
    "        if (not has_tag) and body_imgs:\n",
    "            add_single_image_paragraph(doc, body_imgs.pop(0), width_pct=body_pct, center=True)\n",
    "        done += 1\n",
    "        if chk_pagebreak.value and done < total:\n",
    "            doc.add_page_break()\n",
    "    doc.add_section(); set_section_to_a5(doc.sections[-1])\n",
    "    # å°åº•ï¼šä¸ç¹¼æ‰¿é é¦–é å°¾ä¸¦æ¸…ç©ºï¼Œç¢ºä¿ç„¡é ç¢¼\n",
    "    doc.sections[-1].footer.is_linked_to_previous = False\n",
    "    doc.sections[-1].header.is_linked_to_previous = False\n",
    "    for p in list(doc.sections[-1].footer.paragraphs):\n",
    "        p._element.getparent().remove(p._element)\n",
    "    doc.sections[-1].footer.add_paragraph('')\n",
    "    for p in list(doc.sections[-1].header.paragraphs):\n",
    "        p._element.getparent().remove(p._element)\n",
    "    doc.sections[-1].header.add_paragraph('')\n",
    "    back_size, back_text2 = parse_and_strip_size_anywhere(back_text, default_pt=12)\n",
    "    emit_stream(doc, back_text2, back_size, back_imgs, back_pct, center=True)\n",
    "    if back_imgs: add_single_image_paragraph(doc, back_imgs.pop(0), width_pct=back_pct, center=True)\n",
    "    buf = io.BytesIO(); doc.save(buf); data = buf.getvalue()\n",
    "    _ = Document(io.BytesIO(data))\n",
    "    return data\n",
    "def on_click(_):\n",
    "    with out:\n",
    "        clear_output();\n",
    "        try:\n",
    "            data = build_docx_bytes(); fname = f'a5_book_{int(time.time())}.docx'\n",
    "            display(HTML('<div style=\"color:green;\">å®Œæˆï¼</div>'))\n",
    "            b64=base64.b64encode(data).decode()\n",
    "            display(HTML(f'<a download=\"{fname}\" href=\"data:application/vnd.openxmlformats-officedocument.wordprocessingml.document;base64,{b64}\">ğŸ“¥ é»æ­¤ä¸‹è¼‰ {fname}</a>'))\n",
    "        except Exception as e:\n",
    "            display(HTML(f'<div style=\"color:red;\">å¤±æ•—ï¼š{e}</div>'))\n",
    "btn.on_click(on_click)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, hashlib, shutil\n",
    "import ipywidgets as widgets\n",
    "from pathlib import Path\n",
    "\n",
    "# ç·©å­˜è¨­å®š\n",
    "CACHE_DIR = Path('./.cache_a5app')\n",
    "CACHE_DIR.mkdir(exist_ok=True)\n",
    "p_lite_mode = widgets.Checkbox(value=True, description='è¼•é‡æ¨¡å¼ï¼ˆç¸®åœ–/å£“ç¸®ï¼Œé©åˆæ‰‹æ©Ÿä¸‹è¼‰ï¼‰')\n",
    "display(p_lite_mode)\n",
    "\n",
    "def _hash_key(s: str) -> str:\n",
    "    return hashlib.md5(s.encode('utf-8')).hexdigest()\n",
    "\n",
    "def cache_put_bytes(key: str, data: bytes) -> Path:\n",
    "    p = CACHE_DIR / key\n",
    "    with open(p, 'wb') as f: f.write(data)\n",
    "    return p\n",
    "\n",
    "def cache_get_path(key: str) -> Path:\n",
    "    p = CACHE_DIR / key\n",
    "    return p if p.exists() else None\n",
    "\n",
    "# é‡å° TTSï¼šåŒ…ä¸€å±¤å¿«å–\n",
    "def synth_speech_to_mp3_cached(text: str, out_path: str, resolve_params_func=None):\n",
    "    if resolve_params_func is None:\n",
    "        # å‘å¾Œç›¸å®¹ï¼šå¦‚æœä½ çš„ç’°å¢ƒå·²æœ‰ resolve_voice_params()\n",
    "        resolve_params_func = globals().get('resolve_voice_params')\n",
    "    params = resolve_params_func() if resolve_params_func else {'engine':'gtts','lang':'zh-TW','tld':'com.tw','slow':False}\n",
    "    sig = f\"{params}|{text}\"\n",
    "    key = _hash_key(sig) + '.mp3'\n",
    "    cached = cache_get_path(key)\n",
    "    if cached:\n",
    "        # å·²æœ‰ç·©å­˜ï¼Œç›´æ¥è¤‡è£½\n",
    "        shutil.copyfile(cached, out_path)\n",
    "        return out_path\n",
    "    # ç”ŸæˆéŸ³æª”ï¼ˆæ²¿ç”¨ä½ ç¾æœ‰çš„ synth_speech_to_mp3 æˆ–å…§å»ºç°¡æ˜“ç‰ˆï¼‰\n",
    "    if 'synth_speech_to_mp3' in globals():\n",
    "        synth_speech_to_mp3(text, out_path)\n",
    "    else:\n",
    "        # Fallback: æœ€ç°¡å–® gTTS\n",
    "        from gtts import gTTS\n",
    "        gTTS(text=text, lang=params.get('lang','zh-TW'), tld=params.get('tld','com.tw'), slow=params.get('slow',False)).save(out_path)\n",
    "    # æ”¾å…¥å¿«å–\n",
    "    with open(out_path, 'rb') as f:\n",
    "        cache_put_bytes(key, f.read())\n",
    "    return out_path\n",
    "\n",
    "# å½±åƒå£“ç¸®å·¥å…·ï¼ˆPillowï¼‰\n",
    "def compress_image_for_mobile(img_pil, max_w=1280, quality=72):\n",
    "    if not p_lite_mode.value:\n",
    "        return img_pil\n",
    "    w, h = img_pil.size\n",
    "    if w > max_w:\n",
    "        nh = int(h * max_w / w)\n",
    "        img_pil = img_pil.resize((max_w, nh))\n",
    "    from io import BytesIO\n",
    "    buf = BytesIO()\n",
    "    img_pil.save(buf, format='JPEG', quality=quality, optimize=True)\n",
    "    buf.seek(0)\n",
    "    from PIL import Image\n",
    "    return Image.open(buf)\n",
    "\n",
    "# å½±ç‰‡åƒæ•¸ï¼ˆè¼•é‡ï¼‰\n",
    "VIDEO_FPS = 24\n",
    "VIDEO_BITRATE = '1000k' if p_lite_mode.value else '2500k'\n",
    "\n",
    "print('âœ… ç·©å­˜/è¼•é‡æ¨¡å¼å·¥å…·å°±ç·’ï¼š', CACHE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx.oxml import OxmlElement\n",
    "from docx.oxml.ns import qn\n",
    "def set_page_num_start(section, start=1):\n",
    "    sectPr = section._sectPr\n",
    "    pgNumType = sectPr.find(qn('w:pgNumType'))\n",
    "    if pgNumType is None:\n",
    "        pgNumType = OxmlElement('w:pgNumType')\n",
    "        sectPr.append(pgNumType)\n",
    "    pgNumType.set(qn('w:start'), str(int(start)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}